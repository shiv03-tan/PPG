# -*- coding: utf-8 -*-
"""segmentation .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ktwewSmeR-gxmCFgYYNdlboAmgwBKUUy

```**bold text**
#import libraries 
```
"""

pip install tabulate

import pandas as pd
import scipy.io
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.signal import butter, lfilter
from scipy.signal import find_peaks
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

"""#load the file"""

mat_file = scipy.io.loadmat(r'/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']

s1=signal1[1,0,0]
s1=np.reshape(s1, 9240)

# Remove DC offsets
s1 = s1 - np.mean(s1)

for i in range(100):
    s = signal1[i, 0, 0]
    slen = len(s[0])
    s = np.reshape(s, slen)
    s = s - np.mean(s)
    signal1[i, 0, 0] = s
    
    s = s / np.max(np.abs(s))

print(    signal1[99, 0, 0])
#plt.plot(signal1[99, 0, 0])

"""removing noise using butterworth filter 

"""

# Apply a Butterworth bandpass filter
low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
high_cutoff_freq = 10 # Cutoff frequency for high-pass filter in Hz
sampling_rate = 100 # Sampling rate is the number of samples per second
nyquist_freq = 0.5 * sampling_rate
low_normal_cutoff = low_cutoff_freq / nyquist_freq
high_normal_cutoff = high_cutoff_freq / nyquist_freq

# Generate filter coefficients
b, a = butter(4, [low_normal_cutoff, high_normal_cutoff], btype='band')

# Apply the filter to the signal
filtered_signal = lfilter(b, a, s)

# Plot the pre-processed signal
plt.figure(2)
plt.xlim(1,800)
plt.plot(filtered_signal)
plt.title('Pre-processed PPG Signal')
plt.show()

"""compare """

import matplotlib.pyplot as plt

# Load the data
mat_file = scipy.io.loadmat('/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']

# Extract the first signal and preprocess it
s = signal1[1, 0, 0]
s = np.reshape(s, 9240)
s = s - np.mean(s)

# Plot the original signal
plt.figure(figsize=(10, 6))
plt.plot(s)
plt.title('Original PPG Signal')

# Apply a Butterworth bandpass filter
low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
high_cutoff_freq = 5 # Cutoff frequency for high-pass filter in Hz
sampling_rate = 100 # Sampling rate is the number of samples per second
nyquist_freq = 0.5 * sampling_rate
low_normal_cutoff = low_cutoff_freq / nyquist_freq
high_normal_cutoff = high_cutoff_freq / nyquist_freq

# Generate filter coefficients
b, a = butter(4, [low_normal_cutoff, high_normal_cutoff], btype='band')

# Apply the filter to the signal
filtered_signal = lfilter(b, a, s)

# Plot the pre-processed signal
plt.figure(figsize=(10, 6))
plt.plot(filtered_signal)
plt.title('Filtered PPG Signal')

# Show the plots
plt.show()

"""Compute analysis indicators"""

# Compute analysis indicators
avg = np.mean(filtered_signal)
std = np.std(filtered_signal)
var = np.var(filtered_signal)
entropy = -np.sum(np.square(filtered_signal) * np.log(np.square(filtered_signal)))
mean = np.mean(np.abs(filtered_signal))
peak_to_peak = np.max(filtered_signal) - np.min(filtered_signal)

# Print analysis indicators
print('Average:', avg)
print('Standard deviation:', std)
print('Variance:', var)
print('Entropy:', entropy)
print('Mean:', mean)
print('Peak-to-peak:', peak_to_peak)

from tabulate import tabulate
# Segment the signal into individual heart beats
window_length = 150 # Length of each heart beat window
step_size = 75 # Step size for sliding window
heart_beats = []
for i in range(0, len(filtered_signal) - window_length, step_size):
    window = filtered_signal[i:i+window_length]
    heart_beats.append(window)

# Find the systolic and diastolic peaks, and systolic and diastolic feet for each heart beat
systolic_peaks = []
diastolic_peaks = []
systolic_feet = []
diastolic_feet = []
notch_points = []
for beat in heart_beats:
    max_idx = np.argmax(beat)
    min_idx = np.argmin(beat)
    notch_idx = max_idx + np.argmin(beat[max_idx:])
    systolic_peaks.append(beat[max_idx])
    diastolic_peaks.append(beat[min_idx])
    systolic_feet.append(beat[notch_idx])
    diastolic_feet.append(beat[min_idx:][0])
    notch_points.append(notch_idx)

# Calculate the pulse peak-to-peak amplitude and P value for each heart beat
pulse_ppa = []
p_values = []
for i in range(len(heart_beats)-1):
    peak1 = systolic_peaks[i]
    peak2 = systolic_peaks[i+1]
    trough1 = diastolic_peaks[i]
    trough2 = diastolic_peaks[i+1]
    if i < len(heart_beats)-2: # Discard last feature as it is not available for last heart beat
        pulse_ppa.append(peak2 - peak1)
        p_values.append(trough2 - trough1)
'''
# Print the extracted features for each heart beat
for i in range(len(heart_beats)):
    print(f"Heart beat {i+1}:")
    print(f"Systolic peak: {systolic_peaks[i]}")
    print(f"Diastolic peak: {diastolic_peaks[i]}")
    print(f"Systolic foot: {systolic_feet[i]}")
    print(f"Diastolic foot: {diastolic_feet[i]}")
    print(f"Notch point: {notch_points[i]}")
    print(f"Pulse peak-to-peak amplitude: {pulse_ppa[i] if i < len(pulse_ppa) else 'N/A'}")
    print(f"P value: {p_values[i] if i < len(p_values) else 'N/A'}")
'''
# Create a list of lists with the extracted features for each heart beat
table_data = []
for i in range(len(heart_beats)):
    row = [        f"Heart beat {i+1}",        systolic_peaks[i],
        diastolic_peaks[i],
        systolic_feet[i],
        diastolic_feet[i],
        notch_points[i],
        pulse_ppa[i] if i < len(pulse_ppa) else 'N/A',
        p_values[i] if i < len(p_values) else 'N/A'
    ]
    table_data.append(row)

# Print the table
headers = ["Heart Beat", "Systolic Peak", "Diastolic Peak", "Systolic Foot", "Diastolic Foot", "Notch Point", "Pulse Peak-to-Peak Amplitude", "P Value"]
print(tabulate(table_data, headers=headers))

import pandas as pd
from tabulate import tabulate

# Segment the signal into individual heart beats
window_length = 150 # Length of each heart beat window
step_size = 75 # Step size for sliding window
heart_beats = []
for i in range(0, len(filtered_signal) - window_length, step_size):
    window = filtered_signal[i:i+window_length]
    heart_beats.append(window)

# Find the systolic and diastolic peaks, and systolic and diastolic feet for each heart beat
systolic_peaks = []
diastolic_peaks = []
systolic_feet = []
diastolic_feet = []
notch_points = []
for beat in heart_beats:
    max_idx = np.argmax(beat)
    min_idx = np.argmin(beat)
    notch_idx = max_idx + np.argmin(beat[max_idx:])
    systolic_peaks.append(beat[max_idx])
    diastolic_peaks.append(beat[min_idx])
    systolic_feet.append(beat[notch_idx])
    diastolic_feet.append(beat[min_idx:][0])
    notch_points.append(notch_idx)

# Calculate the pulse peak-to-peak amplitude and P value for each heart beat
pulse_ppa = []
p_values = []
for i in range(len(heart_beats)-1):
    peak1 = systolic_peaks[i]
    peak2 = systolic_peaks[i+1]
    trough1 = diastolic_peaks[i]
    trough2 = diastolic_peaks[i+1]
    if i < len(heart_beats)-2: # Discard last feature as it is not available for last heart beat
        pulse_ppa.append(peak2 - peak1)
        p_values.append(trough2 - trough1)

# Create a list of lists with the extracted features for each heart beat
table_data = []
for i in range(len(heart_beats)):
    row = [
        f"Heart beat {i+1}",
        systolic_peaks[i],
        diastolic_peaks[i],
        systolic_feet[i],
        diastolic_feet[i],
        notch_points[i],
        pulse_ppa[i] if i < len(pulse_ppa) else 'N/A',
        p_values[i] if i < len(p_values) else 'N/A'
    ]
    table_data.append(row)

# Convert the list of lists to a DataFrame
df = pd.DataFrame(table_data, columns=headers)

# Save the DataFrame to an Excel file
df.to_excel('heart_beat_data.xlsx', index=False)

# Plot the original signal with features marked
plt.figure(figsize=(10, 6))
plt.plot(filtered_signal)

for i in range(len(systolic_peaks)):
    plt.plot(notch_points[i], systolic_feet[i], 'o', color='green')
    plt.plot(notch_points[i], diastolic_feet[i], 'o', color='red')
    plt.plot(np.arange(notch_points[i], len(heart_beats[i])), [systolic_peaks[i]]*(len(heart_beats[i])-notch_points[i]), color='green')
    plt.plot(np.arange(notch_points[i], len(heart_beats[i])), [diastolic_peaks[i]]*(len(heart_beats[i])-notch_points[i]), color='red')

plt.title('Filtered PPG Signal with Features Marked')
plt.xlim(1,8000)
plt.xlabel('Sample')
plt.ylabel('Amplitude')
plt.grid()
plt.show()

# Plot the pulse peak-to-peak amplitude and P value for each heart beat
plt.figure(figsize=(10, 6))
plt.plot(pulse_ppa)
plt.title('Pulse Peak-to-Peak Amplitude')
plt.xlabel('Heart Beat')
plt.ylabel('Amplitude')
plt.grid()
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(p_values)
plt.title('P Value')
plt.xlabel('Heart Beat')
plt.ylabel('Amplitude')
plt.grid()
plt.show()

print(len(systolic_peaks))
print(len(diastolic_peaks))

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import scipy.io

# Load the dataset
mat_file = scipy.io.loadmat('/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']
# convert the signal data into a pandas DataFrame
X = pd.DataFrame(signal1.reshape(-1, signal1.shape[-1]))
y = np.ones(len(X))
y[len(X)//2:] = 0 # Assign 0 to second half of the heart beats as they belong to a different individual

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest model
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Evaluate the model on the testing set
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

# Load the dataset
mat_file = scipy.io.loadmat(r'/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']
# convert the signal data into a pandas DataFrame
X = pd.DataFrame(signal1.reshape(-1, signal1.shape[-1]))
y = np.ones(len(X))
y[len(X)//2:] = 0 # Assign 0 to second half of the heart beats as they belong to a different individual

# Extract the features for each heart beat
heart_beats = []
max_length = max([len(s) for s in signal1])

for i in range(len(signal1)):
    s = signal1[i, 0, 0]
    s = np.reshape(s, -1)
    s = s - np.mean(s)
    padded_s = np.zeros(max_length)
    padded_s[:len(s)] = s
    signal1[i, 0, 0] = padded_s

    # Apply a Butterworth bandpass filter
    low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
    high_cutoff_freq = 5 # Cutoff frequency for high-pass filter in Hz
    sampling_rate = 100 # Sampling rate is the number of samples per second
    nyquist_freq = 0.5 * sampling_rate
    low_normal_cutoff = low_cutoff_freq / nyquist_freq
    high_normal_cutoff = high_cutoff_freq / nyquist_freq
    # Generate filter coefficients
    b, a = butter(4, [low_normal_cutoff, high_normal_cutoff], btype='band')
    # Apply the filter to the signal
    filtered_signal = lfilter(b, a, s)
    # Segment the signal into individual heart beats
    window_length = 150 # Length of each heart beat window
    step_size = 75 # Step size for sliding window
    for i in range(0, len(filtered_signal) - window_length, step_size):
        window = filtered_signal[i:i+window_length]
        heart_beats.append(window)
        
systolic_peaks = []
diastolic_peaks = []
systolic_feet = []
diastolic_feet = []
notch_points = []
pulse_ppa = []
p_values = []
for beat in heart_beats:
    max_idx = np.argmax(beat)
    min_idx = np.argmin(beat)
    notch_idx = max_idx + np.argmin(beat[max_idx:])
    systolic_peaks.append(beat[max_idx])
    diastolic_peaks.append(beat[min_idx])
    systolic_feet.append(beat[notch_idx])
    diastolic_feet.append(beat[min_idx:][0])
    notch_points.append(notch_idx)
for i in range(len(heart_beats)-1):
    peak1 = systolic_peaks[i]
    peak2 = systolic_peaks[i+1]
    trough1 = diastolic_peaks[i]
    trough2 = diastolic_peaks[i+1]
    if i < len(heart_beats)-2: # Discard last feature as it is not available for last heart beat
        pulse_ppa.append(peak2 - peak1)
        p_values.append(trough2 - trough1)

df = pd.DataFrame({
'Systolic Peak': systolic_peaks[:-1],
'Diastolic Peak': diastolic_peaks[:-1],
'Systolic Foot': systolic_feet[:-1],
'Diastolic Foot': diastolic_feet[:-1],
'Notch Point': notch_points[:-1],
'Pulse Peak-to-Peak Amplitude': pulse_ppa,
'P Value': p_values
})
df['Target'] = np.ones(len(df))
df['Target'][len(df)//2:] = 0
X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=42)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.metrics import confusion_matrix

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)