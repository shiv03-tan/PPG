# -*- coding: utf-8 -*-
"""11/4(7:57).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11he0Yjtv0bBDD7gwYQjuqncIfGgQw-Vd

**loading libraries**
"""

import pandas as pd
import scipy.io
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.signal import butter, lfilter
from scipy.signal import find_peaks
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

"""**Loading dataset**"""

mat_file = scipy.io.loadmat(r'/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']

#
plt.figure(1)
plt.xlim(10,1000)
plt.plot(s1,'-g')
# plt.plot(s3,'-r')
plt.title('Normalized Raw PPG Signal (removed DC offset)')
plt.show()

s1=signal1[1,0,0]
s1=np.reshape(s1, 9240)

# Remove DC offsets
s1 = s1 - np.mean(s1)

for i in range(100):
    s = signal1[i, 0, 0]
    slen = len(s[0])
    s = np.reshape(s, slen)
    s = s - np.mean(s)
    signal1[i, 0, 0] = s
    
    s = s / np.max(np.abs(s))

print(    signal1[99, 0, 0])
#plt.plot(signal1[99, 0, 0])

#a = signal1[50,0,0]
#v = signal1[i,0,0]

def NormaliseCrossCorrelation(a,v):
    M = len(a)
    N = len(v)
    print(M,N)
    r=0
    if type(a) is list: 
        a = np.array(a)
    if type(v) is list: 
        v = np.array(v)
    
    v_mu = np.mean(v)

    ncc_series = []
    for i in range(M-N+1):
        _a = a[i:i+N]
        a_sum = _a - np.mean(a)
        v_sum = v - v_mu
        #if(a_sum != 0 and v_sum != 0 and N != 0):
        nr = 1/N * np.sum(a_sum*v_sum) / np.sqrt(np.var(a)*np.var(v))
        ncc_series.append(nr)
    if (len(ncc_series) != 0):
      r=sum(ncc_series)/len(ncc_series)
  
    return r

#print(signal1[1, 0, 0])
result=[]
for i in range (1,100):
  ncc_series = NormaliseCrossCorrelation(signal1[50, 0, 0],signal1[i, 0, 0])
  result.append(ncc_series)

print(ncc_series)
plt.plot( result, '*r')
plt.xlabel('Lag')
plt.ylabel('Normalized Cross-Correlation')
plt.title('Normalized Cross-Correlation of a and v')
plt.show()

def NormaliseCrossConvolution(a,v):
    M = len(a)
    N = len(v)

    if type(a) is list: 
        a = np.array(a)
    if type(v) is list: 
        v = np.array(v)
    
    v_mean = np.mean(v)
    a_normalized = a - np.mean(a)
    v_normalized = v - v_mean
    corr = np.convolve(a_normalized, v_normalized, mode='valid')
    corr /= np.sqrt(np.sum(np.square(a_normalized)) * np.sum(np.square(v_normalized)))
    return corr

ncc_series=[]
for i in range (1,100):
  ncc_series = NormaliseCrossConvolution(signal1[50, 0, 0],signal1[i, 0, 0])
  result.append(ncc_series)

print(ncc_series)
plt.plot(ncc_series, '*r')
plt.xlabel('Lag')
plt.ylabel('NormaliseCrossConvolution')
plt.title('NormaliseCrossConvolution')
plt.show()

plt.figure(1)
plt.xlim(10,800)
plt.plot(s,'-g')
# plt.plot(s3,'-r')
plt.title('Normalized Raw PPG Signal (removed DC offset)')
plt.show()

# Remove both low and high frequency noise
low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
high_cutoff_freq = 10 # Cutoff frequency for high-pass filter in Hz
sampling_rate = 100 # Sampling rate is the number of samples per second
nyquist_freq = 0.5 * sampling_rate
low_normal_cutoff = low_cutoff_freq / nyquist_freq
high_normal_cutoff = high_cutoff_freq / nyquist_freq

# Apply Butterworth filter to remove low-frequency noise
b_low, a_low = butter(4, low_normal_cutoff, btype='low')
filtered_signal1 = lfilter(b_low, a_low, s)

# Apply Butterworth filter to remove high-frequency noise
b_high, a_high = butter(4, high_normal_cutoff, btype='high')
filtered_signal2 = lfilter(b_high, a_high, filtered_signal1)

import matplotlib.pyplot as plt

# Plot the original signal
plt.plot(s, label='Original Signal')

# Plot the filtered signal
plt.plot(filtered_signal2, label='Filtered Signal')
plt.plot(filtered_signal1, label='Filtered Signal')

# Set the plot title and axis labels
plt.title('Signal with Low and High Frequency Noise Removed')
plt.xlim(10,800)
plt.xlabel('Time (samples)')
plt.ylabel('Amplitude')

# Show the legend
plt.legend()

# Show the plot
plt.show()

"""**removing noise using buterworth bandpass filter**"""

# Apply a Butterworth bandpass filter
low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
high_cutoff_freq = 10 # Cutoff frequency for high-pass filter in Hz
sampling_rate = 100 # Sampling rate is the number of samples per second
nyquist_freq = 0.5 * sampling_rate
low_normal_cutoff = low_cutoff_freq / nyquist_freq
high_normal_cutoff = high_cutoff_freq / nyquist_freq

# Generate filter coefficients
b, a = butter(4, [low_normal_cutoff, high_normal_cutoff], btype='band')

# Apply the filter to the signal
filtered_signal = lfilter(b, a, s)

# Plot the pre-processed signal
plt.figure(2)
plt.xlim(1,800)
plt.plot(filtered_signal)
plt.title('Pre-processed PPG Signal')
plt.show()

import matplotlib.pyplot as plt

# Load the data
mat_file = scipy.io.loadmat('/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']

# Extract the first signal and preprocess it
s = signal1[1, 0, 0]
s = np.reshape(s, 9240)
s = s - np.mean(s)

# Plot the original signal
plt.figure(figsize=(10, 6))
plt.plot(s)
plt.title('Original PPG Signal')

# Apply a Butterworth bandpass filter
low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
high_cutoff_freq = 10 # Cutoff frequency for high-pass filter in Hz
sampling_rate = 100 # Sampling rate is the number of samples per second
nyquist_freq = 0.5 * sampling_rate
low_normal_cutoff = low_cutoff_freq / nyquist_freq
high_normal_cutoff = high_cutoff_freq / nyquist_freq

# Generate filter coefficients
b, a = butter(4, [low_normal_cutoff, high_normal_cutoff], btype='band')

# Apply the filter to the signal
filtered_signal = lfilter(b, a, s)

# Plot the pre-processed signal
plt.figure(figsize=(10, 6))
plt.plot(filtered_signal)
plt.title('Filtered PPG Signal')

# Show the plots
plt.show()

"""**Compute analysis indicators**"""

# Compute analysis indicators
avg = np.mean(filtered_signal)
std = np.std(filtered_signal)
var = np.var(filtered_signal)
entropy = -np.sum(np.square(filtered_signal) * np.log(np.square(filtered_signal)))
mean = np.mean(np.abs(filtered_signal))
peak_to_peak = np.max(filtered_signal) - np.min(filtered_signal)

# Print analysis indicators
print('Average:', avg)
print('Standard deviation:', std)
print('Variance:', var)
print('Entropy:', entropy)
print('Mean:', mean)
print('Peak-to-peak:', peak_to_peak)

import matplotlib.pyplot as plt

# Compute analysis indicators
avg = np.mean(filtered_signal)
std = np.std(filtered_signal)
var = np.var(filtered_signal)
entropy = -np.sum(np.square(filtered_signal) * np.log(np.square(filtered_signal)))
mean = np.mean(np.abs(filtered_signal))
peak_to_peak = np.max(filtered_signal) - np.min(filtered_signal)

# Create a bar plot
labels = ['Average', 'Standard deviation', 'Variance', 'Entropy', 'Mean', 'Peak-to-peak']
values = [avg, std, var, mean, entropy, peak_to_peak]
plt.bar(labels, values)
print(labels, values)

# Add labels and a title to the plot
plt.xlabel('Analysis Indicators')
plt.ylabel('Value')
plt.title('Signal Analysis Indicators')

# Show the plot
plt.show()

import matplotlib.pyplot as plt

# Compute analysis indicators
avg = np.mean(filtered_signal)
std = np.std(filtered_signal)
var = np.var(filtered_signal)
entropy = -np.sum(np.square(filtered_signal) * np.log(np.square(filtered_signal)))
mean = np.mean(np.abs(filtered_signal))
peak_to_peak = np.max(filtered_signal) - np.min(filtered_signal)

# Plot each analysis indicator separately
plt.figure(figsize=(10, 6))

plt.subplot(2, 3, 1)
plt.plot(filtered_signal)
plt.title('Filtered Signal')

plt.subplot(2, 3, 2)
plt.bar('Average', avg)
plt.title('Average')

plt.subplot(2, 3, 3)
plt.bar('Standard deviation', std)
plt.title('Standard deviation')

plt.subplot(2, 3, 4)
plt.bar('Variance', var)
plt.title('Variance')

plt.subplot(2, 3, 5)
plt.bar('Entropy', entropy)
plt.title('Entropy')

plt.subplot(2, 3, 6)
plt.bar('Mean', mean)
plt.bar('Peak-to-peak', peak_to_peak)
plt.title('Mean and Peak-to-peak')

# Show the plots
plt.tight_layout()
plt.show()

#Apply a low-pass filter to remove high-frequency noise from the signal.
# Remove high-frequency noise
cutoff_freq = 0.5 # Cutoff frequency in Hz
sampling_rate = 100 # Sampling rate is the number of samples per second
nyquist_freq = 0.5 * sampling_rate
normal_cutoff = cutoff_freq / nyquist_freq
b, a = butter(1, 3, btype='high', analog=True)
filtered_signal1 = lfilter(b, a, s )

# Plot the pre-processed signal
plt.figure(2)
plt.xlim(1,800)
plt.plot(filtered_signal1)
plt.title('Pre-processed PPG Signal')
plt.show()

"""**Segmentation**"""

segment_length = 100 # Length of each segment
segmented_signal = [] # List to hold the segmented signal

for i in range(0, len(filtered_signal), segment_length):
    # Find peaks in the current segment
    segment_peaks, _ = find_peaks(filtered_signal[i:i+segment_length])
    
    # Add the segment to the segmented signal list
    segmented_signal.append(filtered_signal[i:i+segment_length][segment_peaks])

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

# Plot the original signal in blue
plt.plot(filtered_signal, '-b')

# Plot each segment in red
for segment in segmented_signal:
    plt.plot(segment, '-r')

plt.xlabel('Time (samples)')
plt.ylabel('Amplitude')
plt.title('Segmented Signal')
plt.show()

print(filtered_signal1)

"""**Find peaks and dips**"""

# Find peaks and dips
peaks, _ = find_peaks(filtered_signal, distance= 20)
peaks = peaks[3:] # Only include peaks from the 4th peak onwards
s=filtered_signal1[peaks[0]:]

# Plot the signal and the detected peaks and dips
fig, ax = plt.subplots(figsize=(20,10))
plt.xlim(1,8000)
ax.plot(filtered_signal , '-g', label='Filtered PPG signal')
ax.plot(peaks, filtered_signal[peaks], 'r*', label='Peaks')
ax.set_ylabel('Amplitude')
plt.title('Feature Extraction PPG Signal')
ax.legend()
plt.show()

print(filtered_signal[peaks])

dips, _ = find_peaks(-filtered_signal, distance= 25)
#peaks, _ = find_peaks(filtered_signal1, distance= 20)
systolic_peaks, _ = find_peaks(filtered_signal, distance=20 )
diastolic_peaks, _ = find_peaks(-filtered_signal, distance=15)
systolic_foots, _ = find_peaks(-filtered_signal, distance= 10)
diastolic_foots, _ = find_peaks(filtered_signal, distance= 15)
s=filtered_signal[dips[4]:]

print(dips)

# Plot the signal and the detected peaks and dips
fig, ax = plt.subplots(figsize=(20,10))
plt.xlim(0,8000)
#ax.plot(s, 'b', label='Raw PPG signal')
ax.plot(filtered_signal , 'g', label='Filtered PPG signal')
#ax.plot(peaks, filtered_signal[peaks], 'r*', label='Peaks')
ax.plot(dips, filtered_signal[dips], 'ko', label='Dips')
ax.plot(systolic_peaks, filtered_signal[systolic_peaks], 'yo', label='Systolic peaks')
ax.plot(diastolic_peaks, filtered_signal[diastolic_peaks], 'mo', label='Diastolic peaks')
ax.plot(systolic_foots, filtered_signal[systolic_foots], 'o', label='systolic_foots')
ax.plot(diastolic_foots, filtered_signal[diastolic_foots], 'p', label='diastolic_foots')
ax.set_xlabel('Sample number')
ax.set_ylabel('Amplitude')
plt.title('Feature Extraction PPG Signal')
ax.legend()
plt.show()

a = signal1[1:-1]
v = signal1[1:-1]



import numpy as np

# Define the signals
num_signals = 100
signal_length = 1000
signals = np.random.randn(num_signals, signal_length)

# Define the filter
filter_length = 100
filter_signal = np.random.randn(filter_length)

# Preprocess the filter
filter_signal -= np.mean(filter_signal)
filter_signal /= np.linalg.norm(filter_signal)

# Preprocess each signal
preprocessed_signals = []
for signal in signals:
    signal -= np.mean(signal)
    signal /= np.linalg.norm(signal)
    preprocessed_signals.append(signal)

# Compute the same normalized cross-correlation for filtered_signal[1] and all other signals
result = []
for i in range(num_signals):
    if i != 1:  # skip the second signal, which is the filtered signal
        x = preprocessed_signals[i]
        corr = np.correlate(x, filter_signal, mode='valid')
        norm = np.linalg.norm(x) * np.linalg.norm(filter_signal)
        result.append(corr / norm)

# Print the result
print(result)

def NormaliseCrossCorrelation(a, v):
    M = len(a)
    if isinstance(v, np.ndarray):
        N = v.shape[0]
    elif isinstance(v, np.float64):
        N = 1
    else:
        raise TypeError('v must be a numpy array or scalar')
        
    if isinstance(a, list):
        a = np.array(a)

import numpy as np
#a = signal1[1,0,0]
#v = signal1[2,0,0]
#print(a)
#print(v)
ncc_series = NormaliseCrossCorrelation(a, v)
print(ncc_series)
# Initialize correlation matrix
#corr_matrix = np.zeros((n_signals, n_signals))
"""
# Compute cross-correlation for each pair of signals
for i in range(10):
  v = signal1[i]
  ncc_series = NormaliseCrossCorrelation(a, v)
  print(ncc_series)
"""

import numpy as np

def normalisecrosscorrelation(subjects, template):
    """
    Perform normalized cross-correlation between a template and multiple subjects.

    Args:
    subjects: a list of numpy arrays, where each array represents a subject's data.
    template: a numpy array representing the template to cross-correlate with.

    Returns:
    A list of normalized cross-correlation values for each subject.
    """
    n_subjects = len(subjects)
    n_template = len(template)

    corr_values = []
    for i in range(n_subjects):
        # Calculate cross-correlation between the template and the subject's data
        corr = np.correlate(subjects[i], template, mode='same')
        
        # Normalize the cross-correlation value
        norm_corr = corr / (np.linalg.norm(subjects[i]) * np.linalg.norm(template))

        # Save the normalized cross-correlation value
        corr_values.append(norm_corr)

    return corr_values

import numpy as np
import matplotlib.pyplot as plt

# Define the number of subjects
num_subjects = 5

# Define the function to calculate the normalized cross-correlation
def normalisecrosscorrelation(x, y):
    x = x - np.mean(x)
    y = y - np.mean(y)
    corr = np.correlate(x, y, mode='full')
    return corr / (np.std(x) * np.std(y))

# Generate random data for demonstration purposes
data = np.random.randn(num_subjects, 1000)

# Loop over the subjects and calculate the cross-correlation
for i in range(num_subjects):
    for j in range(num_subjects):
        if i != j:
            corr = normalisecrosscorrelation(data[i], data[j])
            plt.plot(corr)

plt.show()

import pandas as pd
import scipy.io
import numpy as np
from scipy.signal import butter, lfilter
from scipy.signal import find_peaks
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
# Load the data
mat_file = scipy.io.loadmat(r'/content/Biosec2_raw_data (2).mat')
signal1 = mat_file['Data_cell']

# Preprocess the data
s1 = signal1[1,0,0]
s1 = np.reshape(s1, 9240)
s1 = s1 - np.mean(s1)
#plt.figure(figsize=(12, 6))
#plt.plot(signal1[1,0,0],'-b')
for i in range(1,100):
    s = signal1[i, 0, 0]
    slen = len(s[0])
    s = np.reshape(s, slen)
    s = s - np.mean(s)
    signal1[i, 0, 0] = s
    
    s = s / np.max(np.abs(s))
#plt.figure(figsize=(12, 6))    
#plt.plot(signal1[1,0,0],'-r')
try:
    # Apply a Butterworth bandpass filter
    low_cutoff_freq = 0.5 # Cutoff frequency for low-pass filter in Hz
    high_cutoff_freq = 10 # Cutoff frequency for high-pass filter in Hz
    sampling_rate = 100 # Sampling rate is the number of samples per second
    nyquist_freq = 0.5 * sampling_rate
    low_normal_cutoff = low_cutoff_freq / nyquist_freq
    high_normal_cutoff = high_cutoff_freq / nyquist_freq

    # Generate filter coefficients
    b, a = butter(4, [low_normal_cutoff, high_normal_cutoff], btype='band')

    # Apply the filter to the signal
    filtered_signal = lfilter(b, a, s)

except Exception as e:
    print("Error:", e)

segment_length = 100 # Length of each segment
segmented_signal = [] # List to hold the segmented signal

for i in range(1, len(filtered_signal), segment_length):
    # Find peaks in the current segment
    segment_peaks, _ = find_peaks(filtered_signal[i:i+segment_length])
    
    # Add the segment to the segmented signal list
    segmented_signal.append(filtered_signal[i:i+segment_length][segment_peaks])

peaks, _ = find_peaks(filtered_signal, distance= 20)
peaks = peaks[3:]
s = filtered_signal[peaks[1]:]

dips, _ = find_peaks(-filtered_signal, distance= 25)
systolic_peaks, _ = find_peaks(filtered_signal, distance=20 )

if len(dips) > 0 and len(systolic_peaks) > 0:
    diastolic_peaks, _ = find_peaks(-filtered_signal, distance=15)
    systolic_foots, _ = find_peaks(-filtered_signal, distance= 10)
    diastolic_foots, _ = find_peaks(filtered_signal, distance= 15)
    s = filtered_signal[dips[4]:]

    features = []
    for i in range(len(dips)-9):
      if dips[i] - dips[i-1] >= 15 and dips[i+1] - dips[i] >= 15:
        systolic_peak = np.max(filtered_signal[systolic_peaks[i]:dips[i]])
        diastolic_peak = np.min(filtered_signal[diastolic_peaks[i]:systolic_peaks[i+1]])
        feature = [systolic_peak, diastolic_peak]
        features.append(feature)

# Prepare the data for classification
X = np.array(features)
y = np.array([1 if i < 50 else 0 for i in range(len(features))])

# Check that X and y have the same number of rows
if X.shape[0] != y.shape[0]:
    print('Error: X and y have different number of samples')
else:
    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    # Normalize the features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Train the SVM model
    svm = SVC(kernel='rbf', gamma='scale')
    svm.fit(X_train, y_train)

    # Make predictions on the test set
    y_pred = svm.predict(X_test)

    # Evaluate the accuracy of the model
    acc = accuracy_score(y_test, y_pred)
    print(f'Accuracy: {acc}')
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of SVM")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

#SVM
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train the SVM classifier
clf = SVC(kernel='rbf', C=1, gamma='scale')
clf.fit(X_train, y_train)

# Predict the test data
y_pred = clf.predict(X_test)


# Evaluate the performance of the classifier
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)
# Make predictions on the test data
y_pred = clf.predict(X_test)


# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Make predictions on the test data
y_pred = clf.predict(X_test)


# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))

# Plot the decision boundary of the SVM classifier
plt.figure(figsize=(8, 6))
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm')
ax = plt.gca()
xlim = ax.get_xlim()
ylim = ax.get_ylim()
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Create a meshgrid to plot the decision boundary
xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 500),
                     np.linspace(ylim[0], ylim[1], 500))
Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Plot the decision boundary and the margins
ax.contour(xx, yy, Z, levels=[-1, 0, 1], linestyles=['--', '-', '--'], alpha=0.5)
ax.set_xlabel('Systolic Peak')
ax.set_ylabel('Diastolic Peak')
ax.set_title('SVM Decision Boundary')

# Show the plot
plt.show()

for idx in incorrect_idx:
    print("Misclassified Sample: {}".format(X_test[idx]))
    print("True Label: {} - Predicted Label: {}%\n".format(y_test[idx], y_pred[idx]))

for idx in correct_idx:
    print("Correctly Classified Sample: {}".format(X_test[idx]))
    print("True Label: {} - Predicted Label: {}%\n".format(y_test[idx], y_pred[idx]))


# Visualize the distribution of the features for each class
plt.figure(figsize=(8, 6))
plt.hist(X_train[y_train == 1, 0], alpha=0.5, label='Class 1', bins=20)
plt.hist(X_train[y_train == 0, 0], alpha=0.5, label='Class 0', bins=20)
plt.xlabel('Systolic Peak')
plt.ylabel('Frequency')
plt.title('Distribution of Systolic Peak by Class')
plt.legend()
plt.show()

plt.figure(figsize=(8, 6))
plt.hist(X_train[y_train == 1, 1], alpha=0.5, label='Class 1', bins=20)
plt.hist

# RANDOM FOREST
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100)

clf.fit(X_train, y_train)

# Predict the test data
y_pred = clf.predict(X_test)

# Evaluate the performance of the classifier
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy random forest:', accuracy)

# Make predictions on the test data
y_pred = clf.predict(X_test)


# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of Random Forest")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

#KNN
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
# Train the KNN classifier
from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier(n_neighbors=10)
clf.fit(X_train, y_train)


# Predict the test data
y_pred = clf.predict(X_test)

# Evaluate the performance of the classifier
accuracy = accuracy_score(y_test, y_pred)
print(' KNN Accuracy:', accuracy)
# Make predictions on the test data
y_pred = clf.predict(X_test)


# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of KNN")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

# Train the classifier
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

# Predict the test data
y_pred = clf.predict(X_test)


# Evaluate the performance of the classifier
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)
# Make predictions on the test data
y_pred = clf.predict(X_test)


# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))
from sklearn.metrics import confusion_matrix

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of DecisionTree ")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

#LogisticRegression
from sklearn.linear_model import LogisticRegression
clf = LogisticRegression()
clf.fit(X_train, y_train)

# Predict the test data
y_pred = clf.predict(X_test)

# Evaluate the performance of the classifier
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)
# Make predictions on the test data
y_pred = clf.predict(X_test)


# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))
# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of  LogisticRegression")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()



from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier()
clf.fit(X_train, y_train)

# Predict the test data
y_pred = clf.predict(X_test)

# Predict the test data
y_pred = clf.predict(X_test)

# Evaluate the performance of the classifier
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy:', accuracy)
# Make predictions on the test data
y_pred = clf.predict(X_test)
from sklearn.metrics import confusion_matrix

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)
import matplotlib.pyplot as plt
import seaborn as sns

# Compute confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix of GradientBoosting ")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()



# Get the indices of the correctly and incorrectly classified samples
correct_idx = np.where(y_pred == y_test)[0]
incorrect_idx = np.where(y_pred != y_test)[0]

# Calculate the number of correctly and incorrectly classified samples
n_correct = len(correct_idx)
n_incorrect = len(incorrect_idx)

# Calculate the accuracy, precision, recall, and F1-score
accuracy = n_correct / len(y_test)
precision = n_correct / (n_correct + n_incorrect)
recall = n_correct / np.sum(y_test)
f1_score = 2 * precision * recall / (precision + recall)

# Print the results
print("Number of correctly classified samples: {}".format(n_correct))
print("Number of incorrectly classified samples: {}".format(n_incorrect))
print("Accuracy: {:.2f}%".format(accuracy*100))
print("Precision: {:.2f}%".format(precision*100))
print("Recall: {:.2f}%".format(recall*100))
print("F1-score: {:.2f}%".format(f1_score*100))
from sklearn.metrics import confusion_matrix



import pandas as pd

# Convert the features list to a pandas DataFrame
df = pd.DataFrame(features, columns=['systolic_peak', 'diastolic_peak'])

# Compute descriptive statistics
print(df.describe())

# Compute correlation matrix
print(df.corr())

# Perform t-test between the systolic_peak and diastolic_peak features
from scipy.stats import ttest_ind
t_stat, p_val = ttest_ind(df['systolic_peak'], df['diastolic_peak'])
print("t-statistic: {:.3f}, p-value: {:.3f}".format(t_stat, p_val))

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
#plt.xlim(10,100)
plt.plot(filtered_signal1)
plt.plot(peaks, filtered_signal[peaks], "x")
plt.plot(dips, filtered_signal[dips], "o")
plt.title("Filtered signal with detected peaks and dips")
plt.xlabel("Sample number")
plt.ylabel("Amplitude")
plt.show()

import matplotlib.pyplot as plt

# Define a range of C values to test
C_range = [0.1, 1, 10, 100, 1000]

# Store the accuracy scores for each C value
accuracy_scores = []

# Iterate over the range of C values
for C_value in C_range:
    # Train the SVM classifier
    clf = SVC(kernel='rbf', C=C_value, gamma='scale')
    clf.fit(X_train, y_train)

    # Predict the test data
    y_pred = clf.predict(X_test)

    # Evaluate the performance of the classifier
    accuracy = accuracy_score(y_test, y_pred)
    
    # Store the accuracy score
    accuracy_scores.append(accuracy)

# Plot the accuracy scores vs C values
plt.plot(C_range, accuracy_scores, '-o')
plt.xscale('log')
plt.xlabel('C')
plt.ylabel('Accuracy')
plt.title('Accuracy vs C')
plt.show()

import pandas as pd
import scipy.io
import numpy as np
from scipy.signal import butter, lfilter, correlate
from scipy.signal import find_peaks
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Load the data
mat_file = scipy.io.loadmat('/content/Biosec2_raw_data (2).mat')
signals = mat_file['Data_cell']

# Preprocess the data
signal1 = signals[1,0,0]
signal1 = np.reshape(signal1, 9240)
signal1 = signal1 - np.mean(signal1)

for i in range(100):
    s = signals[i, 0, 0]
    slen = len(s[0])
    s = np.reshape(s, slen)
    s = s - np.mean(s)
    signals[i, 0, 0] = s
    s = s / np.max(np.abs(s))

# Filter the signal
cutoff_freq = 0.5
sampling_rate = 100
nyquist_freq = 0.5 * sampling_rate
normal_cutoff = cutoff_freq / nyquist_freq
b, a = butter(1, normal_cutoff, btype='low', analog=False)
filtered_signal1 = lfilter(b, a, signal1)

# Find the peaks and foots of the signal
peaks, _ = find_peaks(filtered_signal1, distance= 20)
peaks = peaks[3:]
s = filtered_signal1[peaks[0]:]

dips, _ = find_peaks(-filtered_signal1, distance= 25)
systolic_peaks, _ = find_peaks(filtered_signal1, distance=20 )

if len(dips) > 0 and len(systolic_peaks) > 0:
    diastolic_peaks, _ = find_peaks(-filtered_signal1, distance=15)
    systolic_foots, _ = find_peaks(-filtered_signal1, distance= 10)
    diastolic_foots, _ = find_peaks(filtered_signal1, distance= 15)
    s = filtered_signal1[dips[4]:]

    # Compute the cross-correlation between signal1 and all other signals in the dataset
    cross_corr = []
    for i in range(100):
        if i == 0:
            continue
        signal2 = subjects[i]
        signal2 = np.reshape(signal2, 9000)
        signal2 = signal2 - np.mean(signal2)
        signal2 = signal2 / np.max(np.abs(signal2))
        filtered_signal2 = lfilter(b, a, signal2)
        corr = correlate(filtered_signal1, filtered_signal2, mode='same')
        cross_corr.append(corr)

    # Prepare the data for classification
    X = np.array(cross_corr).T
    y = np.array([1 if i < 50 else 0 for i in range(100)])

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Normalize the features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Train the SVM classifier
    clf = SVC(kernel='rbf', C=1, gamma='scale')

import matplotlib.pyplot as plt
import numpy as np

# Model names and corresponding metric values
models = ['SVM', 'Random Forest', 'KNN', 'Logistic Regression', 'Decision Tree', 'Gradient Boosting']
accuracy = [81.82, 97.73, 90.91, 84.09, 100.00, 100.00]
precision = [81.82, 97.73, 90.91, 84.09, 100.00, 100.00]
recall = [360.00, 430.00, 400.00, 370.00, 440.00, 440.00]
f1_score = [133.33, 159.26, 148.15, 137.04, 162.96, 162.96]

# Setting up the plot
x = np.arange(len(models))
width = 0.1
fig, ax = plt.subplots()
rects1 = ax.bar(x - 1.5*width, accuracy, width, label='Accuracy')
rects2 = ax.bar(x - 0.5*width, precision, width, label='Precision')
rects3 = ax.bar(x + 0.5*width, recall, width, label='Recall')
rects4 = ax.bar(x + 1.5*width, f1_score, width, label='F1-score')

# Adding labels, title, and legend
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.set_xlabel('Models')
ax.set_ylabel('Metric Value')
ax.set_title('Classification Metrics')
ax.legend()

# Displaying the plot
plt.show()

import matplotlib.pyplot as plt

# Model names and corresponding metric values
models = ['SVM', 'Random Forest', 'KNN', 'Logistic Regression', 'Decision Tree', 'Gradient Boosting']
accuracy = [81.82, 97.73, 90.91, 84.09, 100.00, 100.00]
f1_score = [133.33, 159.26, 148.15, 137.04, 162.96, 162.96]

# Setting up the plot
fig, ax = plt.subplots()
ax.scatter(accuracy, f1_score)

# Adding labels, title, and grid lines
ax.set_xlabel('Accuracy')
ax.set_ylabel('F1-score')
ax.set_title('Accuracy vs F1-score')
ax.grid(True)

# Adding model names to data points
for i, model in enumerate(models):
    ax.annotate(model, (accuracy[i], f1_score[i]))

# Displaying the plot
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Define data
classifiers = ["SVM", "Random Forest", "KNN", "Decision Tree", "Logistic Regression", "Gradient Boosting"]
accuracy = [86.36, 100, 95.45, 100, 90.91, 100]
precision = [86.36, 100, 95.45, 100, 90.91, 100]
recall = [1900, 2200, 2100, 2200, 2000, 22000]
f1_score = [165.22, 191.30, 182.61, 191.30, 173.91, 191.30]

# Set width of bars and bar position
bar_width = 0.2
pos = np.arange(len(classifiers))

# Create the figure and axes objects
fig, ax = plt.subplots()

# Plot the data as grouped bars
ax.bar(pos - bar_width, accuracy, bar_width, label="Accuracy")
ax.bar(pos, precision, bar_width, label="Precision")
ax.bar(pos + bar_width, recall, bar_width, label="Recall")
ax.bar(pos + bar_width*2, f1_score, bar_width, label="F1-score")

# Set the labels and title
ax.set_xticks(pos)
ax.set_xticklabels(classifiers)
ax.set_ylabel("Metrics")
ax.set_title("Comparison of Classifiers")
ax.legend()

# Show the plot
plt.show()



import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

# Define data as a pandas DataFrame
data = pd.DataFrame({
    "Classifier": ["SVM", "Random Forest", "KNN", "Decision Tree", "Logistic Regression", "Gradient Boosting"],
    "Accuracy": [86.36, 100, 95.45, 100, 90.91, 100],
    "Precision": [86.36, 100, 95.45, 100, 90.91, 100],
    "Recall": [1900, 2200, 2100, 2200, 2000, 22000],
    "F1-score": [165.22, 191.30, 182.61, 191.30, 173.91, 191.30]
})

# Pivot the data to create a matrix
matrix = data.pivot("Classifier", "Metrics", "Value")

# Generate the heatmap using Seaborn
sns.heatmap(matrix, annot=True, cmap="YlGnBu")

# Set the title and axis labels
plt.title("Comparison of Classifiers")
plt.xlabel("Metrics")
plt.ylabel("Classifier")

# Show the plot
plt.show()